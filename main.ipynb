{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "mount_file_id": "1d2Z2bqySl8xdUlR-1OLPZkxuSC3WJ_QP",
      "authorship_tag": "ABX9TyOwpRIJAhEUV+OaTA+8bkRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshith264/Digitalising-an-offline-Chess-Board-/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxJHiPULl_rQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRQHIt3mdkH"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uecAHTzmgMe"
      },
      "source": [
        "folder = '/content/drive/MyDrive/splitted_data'\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_oL3gJTqRPH"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=5,\n",
        "        # width_shift_range=0.1,\n",
        "        # height_shift_range=0.1,\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6egw_LeqZ4_",
        "outputId": "1f9a8cdd-d346-4305-e61e-31196128b975"
      },
      "source": [
        "train_gen = datagen.flow_from_directory(\n",
        "    folder + '/train',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle=True  \n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    folder + '/test',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle=False \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1597 images belonging to 13 classes.\n",
            "Found 810 images belonging to 13 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xS-AThsz04U",
        "outputId": "e64312aa-00ce-441b-e84a-289ab5b8cfb1"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
        " \n",
        "# Freeze convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False    \n",
        "\n",
        "# Establish new fully connected block\n",
        "x = base_model.output\n",
        "x = Flatten()(x)  # flatten from convolution tensor output  \n",
        "x = Dense(500, activation='relu')(x) # number of layers and units are hyperparameters, as usual\n",
        "x = Dense(500, activation='relu')(x)\n",
        "predictions = Dense(13, activation='softmax')(x) # should match # of classes predicted\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_te-NeFsJ62",
        "outputId": "2c59020f-df72-42fd-9fa4-f5dd4962835b"
      },
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               12544500  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                6513      \n",
            "=================================================================\n",
            "Total params: 27,516,201\n",
            "Trainable params: 12,801,513\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Muvgm-tqol",
        "outputId": "d0c5b3fc-cfd7-4a11-ee67-f68d6f732598"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen, \n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=test_gen\n",
        "    )\n",
        "model.save_weights('model_VGG16.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 658s 13s/step - loss: 3.7139 - categorical_accuracy: 0.1937 - val_loss: 1.4479 - val_categorical_accuracy: 0.4704\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 22s 444ms/step - loss: 1.1079 - categorical_accuracy: 0.6255 - val_loss: 0.9461 - val_categorical_accuracy: 0.6679\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 22s 445ms/step - loss: 0.6010 - categorical_accuracy: 0.8008 - val_loss: 0.7756 - val_categorical_accuracy: 0.7284\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 22s 449ms/step - loss: 0.3918 - categorical_accuracy: 0.8759 - val_loss: 0.6456 - val_categorical_accuracy: 0.7716\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 22s 447ms/step - loss: 0.2761 - categorical_accuracy: 0.9235 - val_loss: 0.5186 - val_categorical_accuracy: 0.8247\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 22s 449ms/step - loss: 0.1941 - categorical_accuracy: 0.9410 - val_loss: 0.5265 - val_categorical_accuracy: 0.8358\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 23s 454ms/step - loss: 0.1654 - categorical_accuracy: 0.9508 - val_loss: 0.5283 - val_categorical_accuracy: 0.8309\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 22s 447ms/step - loss: 0.1738 - categorical_accuracy: 0.9477 - val_loss: 0.5888 - val_categorical_accuracy: 0.8259\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 22s 448ms/step - loss: 0.0955 - categorical_accuracy: 0.9742 - val_loss: 0.9092 - val_categorical_accuracy: 0.7519\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 22s 445ms/step - loss: 0.1826 - categorical_accuracy: 0.9367 - val_loss: 0.5391 - val_categorical_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "waFVLGm6tvCF",
        "outputId": "c38b1f7c-5b0d-45c6-8c38-43f557377b9a"
      },
      "source": [
        "plt.plot(history.history['categorical_accuracy'], 'ko')\n",
        "plt.plot(history.history['val_categorical_accuracy'], 'b')\n",
        "\n",
        "plt.title('Accuracy vs Training Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation']);\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCYWsYfluA2i",
        "outputId": "654e2084-8c0c-49a2-a96f-642b0e3c0487"
      },
      "source": [
        "test_gen.reset()\n",
        "Y_pred = model.predict_generator(test_gen)\n",
        "classes = test_gen.classes[test_gen.index_array]\n",
        "y_pred = np.argmax(Y_pred, axis= -1)\n",
        "# print(sum(y_pred==classes)/810)\n",
        "\n",
        "target_names = ['BB', 'BK', 'BN', 'BP', 'BQ', 'BR', 'Empty', 'WB', 'WK', 'WN', 'WP', 'WQ', 'WR']\n",
        "\n",
        "print(classification_report(test_gen.classes[test_gen.index_array], y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          BB       0.96      0.75      0.84        67\n",
            "          BK       0.73      0.77      0.75        35\n",
            "          BN       0.74      0.83      0.78        58\n",
            "          BP       0.97      0.92      0.94        65\n",
            "          BQ       0.68      0.95      0.79        62\n",
            "          BR       0.84      0.69      0.75        67\n",
            "       Empty       0.97      0.97      0.97        71\n",
            "          WB       0.93      0.71      0.80        72\n",
            "          WK       0.78      0.86      0.82        37\n",
            "          WN       0.74      0.80      0.77        69\n",
            "          WP       0.89      0.87      0.88        67\n",
            "          WQ       0.80      0.88      0.84        67\n",
            "          WR       0.85      0.84      0.84        73\n",
            "\n",
            "    accuracy                           0.83       810\n",
            "   macro avg       0.84      0.83      0.83       810\n",
            "weighted avg       0.85      0.83      0.83       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR_Q0o3QuCwq",
        "outputId": "9ffb5163-0d6a-4968-e95d-11acc4a9be85"
      },
      "source": [
        "base_model_two = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
        " \n",
        "# Freeze convolutional layers\n",
        "for layer in base_model_two.layers:\n",
        "    layer.trainable = False    \n",
        "\n",
        "# Establish new fully connected block\n",
        "x = base_model_two.output\n",
        "x = Flatten()(x)  # flatten from convolution tensor output  \n",
        "x = Dense(500, activation='relu')(x) # number of layers and units are hyperparameters, as usual\n",
        "x = Dense(500, activation='relu')(x)\n",
        "predictions = Dense(13, activation='softmax')(x) # should match # of classes predicted\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGTKyxwLyJ4G",
        "outputId": "119ab4c7-90ba-4289-9567-fe4c8e6a1206"
      },
      "source": [
        "# this is the model we will train\n",
        "model_two = Model(inputs=base_model_two.input, outputs=predictions)\n",
        "model_two.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_two.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               12544500  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 13)                6513      \n",
            "=================================================================\n",
            "Total params: 32,825,897\n",
            "Trainable params: 12,801,513\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7K6iRK3uJxb",
        "outputId": "0fff82f9-9ee7-4684-bcce-d85931989a7e"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model_two.fit(\n",
        "    train_gen, \n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=test_gen\n",
        "    )\n",
        "model.save_weights('model_VGG19.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 25s 478ms/step - loss: 4.0088 - accuracy: 0.1495 - val_loss: 1.7959 - val_accuracy: 0.4321\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 24s 473ms/step - loss: 1.3044 - accuracy: 0.5721 - val_loss: 1.0254 - val_accuracy: 0.6556\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 24s 475ms/step - loss: 0.7652 - accuracy: 0.7206 - val_loss: 0.8286 - val_accuracy: 0.7111\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 24s 471ms/step - loss: 0.5247 - accuracy: 0.8357 - val_loss: 0.7227 - val_accuracy: 0.7272\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 24s 473ms/step - loss: 0.4647 - accuracy: 0.8400 - val_loss: 0.6969 - val_accuracy: 0.7457\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 24s 471ms/step - loss: 0.3133 - accuracy: 0.8914 - val_loss: 0.6869 - val_accuracy: 0.7778\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 24s 471ms/step - loss: 0.2724 - accuracy: 0.9036 - val_loss: 0.6573 - val_accuracy: 0.7864\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 24s 475ms/step - loss: 0.2578 - accuracy: 0.9182 - val_loss: 0.6543 - val_accuracy: 0.7901\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 24s 475ms/step - loss: 0.1409 - accuracy: 0.9665 - val_loss: 0.9943 - val_accuracy: 0.7025\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 24s 473ms/step - loss: 0.2477 - accuracy: 0.9167 - val_loss: 0.7837 - val_accuracy: 0.7716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgZ2shrRv3OY",
        "outputId": "b942fc7d-a3ae-4233-b194-4805aa3bf7eb"
      },
      "source": [
        "test_gen.reset()\n",
        "Y_pred = model_two.predict_generator(test_gen)\n",
        "classes = test_gen.classes[test_gen.index_array]\n",
        "y_pred = np.argmax(Y_pred, axis= -1)\n",
        "\n",
        "\n",
        "print(classification_report(test_gen.classes[test_gen.index_array], y_pred, target_names=target_names))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          BB       0.74      0.76      0.75        67\n",
            "          BK       0.68      0.91      0.78        35\n",
            "          BN       0.60      0.86      0.70        58\n",
            "          BP       0.86      0.94      0.90        65\n",
            "          BQ       0.90      0.71      0.79        62\n",
            "          BR       0.72      0.63      0.67        67\n",
            "       Empty       1.00      0.97      0.99        71\n",
            "          WB       1.00      0.49      0.65        72\n",
            "          WK       0.92      0.32      0.48        37\n",
            "          WN       0.73      0.59      0.66        69\n",
            "          WP       0.78      0.91      0.84        67\n",
            "          WQ       0.66      0.93      0.77        67\n",
            "          WR       0.75      0.89      0.81        73\n",
            "\n",
            "    accuracy                           0.77       810\n",
            "   macro avg       0.80      0.76      0.75       810\n",
            "weighted avg       0.80      0.77      0.76       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bka3hrNwZlp",
        "outputId": "de515e53-5405-4e22-f04e-16b1b59be12f"
      },
      "source": [
        "new_data = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/cropped_images/',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle=False \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 64 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfiUXkFv71k"
      },
      "source": [
        "#for predicting peices from cropped images\n",
        "\n",
        "new_data.reset()\n",
        "Y_pred = model.predict_generator(new_data)\n",
        "classes = new_data.classes[new_data.index_array]\n",
        "y_pred = np.argmax(Y_pred, axis= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l60Bgl44wj0W",
        "outputId": "c5299dd1-0f02-4e4a-909d-60bbc63a9c2b"
      },
      "source": [
        "model3 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
        " \n",
        "# Freeze convolutional layers\n",
        "for layer in model3.layers:\n",
        "    layer.trainable = False    \n",
        "\n",
        "# Establish new fully connected block\n",
        "x = model3.output\n",
        "x = Flatten()(x)  # flatten from convolution tensor output  \n",
        "x = Dense(500, activation='sigmoid')(x) # number of layers and units are hyperparameters, as usual\n",
        "x = Dense(500, activation='sigmoid')(x)\n",
        "predictions = Dense(13, activation='softmax')(x) # should match # of classes predicted\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbIzH3F8fEJt",
        "outputId": "ceb45ed7-1459-427c-b08e-f984a3d728d3"
      },
      "source": [
        "# this is the model we will train\n",
        "model3 = Model(inputs=model3.input, outputs=predictions)\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model3.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               12544500  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                6513      \n",
            "=================================================================\n",
            "Total params: 27,516,201\n",
            "Trainable params: 12,801,513\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A0ixnlEfQqk",
        "outputId": "1364b18d-3add-4f3a-83d5-36c28086c467"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model3.fit(\n",
        "    train_gen, \n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=test_gen\n",
        "    )\n",
        "model3.save_weights('model3_s.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 670s 13s/step - loss: 2.6856 - categorical_accuracy: 0.1114 - val_loss: 2.1804 - val_categorical_accuracy: 0.2321\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 22s 438ms/step - loss: 2.0067 - categorical_accuracy: 0.3307 - val_loss: 1.6042 - val_categorical_accuracy: 0.4321\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 22s 440ms/step - loss: 1.4177 - categorical_accuracy: 0.5129 - val_loss: 1.2194 - val_categorical_accuracy: 0.6074\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 22s 441ms/step - loss: 1.0282 - categorical_accuracy: 0.7076 - val_loss: 0.9920 - val_categorical_accuracy: 0.6963\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 22s 444ms/step - loss: 0.7787 - categorical_accuracy: 0.7615 - val_loss: 0.7637 - val_categorical_accuracy: 0.7556\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 22s 441ms/step - loss: 0.5349 - categorical_accuracy: 0.8777 - val_loss: 0.6888 - val_categorical_accuracy: 0.7889\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 22s 441ms/step - loss: 0.4023 - categorical_accuracy: 0.9197 - val_loss: 0.5960 - val_categorical_accuracy: 0.8025\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 22s 438ms/step - loss: 0.3080 - categorical_accuracy: 0.9351 - val_loss: 0.5225 - val_categorical_accuracy: 0.8296\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 22s 442ms/step - loss: 0.2358 - categorical_accuracy: 0.9667 - val_loss: 0.5651 - val_categorical_accuracy: 0.8025\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 22s 438ms/step - loss: 0.1861 - categorical_accuracy: 0.9642 - val_loss: 0.4765 - val_categorical_accuracy: 0.8519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry7TP_2-hjHB",
        "outputId": "c8f3ca13-5f6a-46ff-ec37-d0ba707ee22a"
      },
      "source": [
        "test_gen.reset()\n",
        "Y_pred = model3.predict_generator(test_gen)\n",
        "classes = test_gen.classes[test_gen.index_array]\n",
        "y_pred = np.argmax(Y_pred, axis= -1)\n",
        "\n",
        "\n",
        "print(classification_report(test_gen.classes[test_gen.index_array], y_pred, target_names=target_names))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          BB       0.98      0.67      0.80        67\n",
            "          BK       0.87      0.77      0.82        35\n",
            "          BN       0.80      0.81      0.80        58\n",
            "          BP       0.95      0.91      0.93        65\n",
            "          BQ       0.82      0.87      0.84        62\n",
            "          BR       0.69      0.91      0.78        67\n",
            "       Empty       1.00      0.97      0.99        71\n",
            "          WB       0.72      0.75      0.73        72\n",
            "          WK       0.92      0.32      0.48        37\n",
            "          WN       0.79      0.75      0.77        69\n",
            "          WP       0.75      0.93      0.83        67\n",
            "          WQ       0.67      0.96      0.79        67\n",
            "          WR       0.93      0.71      0.81        73\n",
            "\n",
            "    accuracy                           0.81       810\n",
            "   macro avg       0.84      0.80      0.80       810\n",
            "weighted avg       0.83      0.81      0.81       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUaCMECfjltQ"
      },
      "source": [
        "model4 = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
        " \n",
        "# Freeze convolutional layers\n",
        "for layer in model4.layers:\n",
        "    layer.trainable = False    \n",
        "\n",
        "# Establish new fully connected block\n",
        "x = model4.output\n",
        "x = Flatten()(x)  # flatten from convolution tensor output  \n",
        "x = Dense(500, activation='sigmoid')(x) # number of layers and units are hyperparameters, as usual\n",
        "x = Dense(500, activation='sigmoid')(x)\n",
        "predictions = Dense(13, activation='softmax')(x) # should match # of classes predicted\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVUCeuVmmco9"
      },
      "source": [
        "# this is the model we will train\n",
        "model4 = Model(inputs=model4.input, outputs=predictions)\n",
        "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xewov_k0mig9"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model4.fit(\n",
        "    train_gen, \n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=test_gen\n",
        "    )\n",
        "model4.save_weights('model3_s.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}